# ğŸ“ Text Summarizer â€” End-to-End NLP Pipeline With LLMs

## ğŸ“Œ Overview

**TextSummarizer** is a modular, production-style Natural Language Processing (NLP) system designed to generate high-quality summaries from long-form input text.  

The project follows a **clean, multi-stage pipeline architecture** commonly used in real-world ML systems and includes:

- ğŸš€ A fully modular NLP pipeline under `src/textSummarizer/`  
- ğŸ“¦ Reusable components for preprocessing, tokenization, and summarization  
- âš™ï¸ YAML-driven configuration (`params.yaml`)  
- ğŸŒ‰ CLI interfaces (`main.py`, `app.py`)
- API included (FastAPI) to serve the model  
- ğŸ³ Dockerized environment for reproducible execution  
- ğŸ§ª Research notebooks & sandbox folder (`research/`)  
- ğŸ“¦ Python packaging (`setup.py`)  
- ğŸ“š Logging, utilities, and entity-based configs like production ML systems  

## ğŸ¯ Problem / Goal

As the amount of digital text grows, organizations need tools that can:

- Reduce reading time  
- Extract essential insights  
- Summarize large documents automatically  
- Deliver consistent results without human bias  

**Goal:** Build a maintainable, modular text summarization system that can be expanded with extractive or abstractive models and integrated into larger applications.


## ğŸ¤– Model Training (PEGASUS-SAMSum)  
The project includes a full training workflow using:

**Model:** `google/pegasus-samsum`  
**Dataset:** Dialogue and conversational corpora (SAMSum-style)  
**Purpose:** Improve summarization performance on unstructured, dialogue-like or mixed-format text.

### ğŸ”§ Training Steps:
- Tokenization + preprocessing  
- Input/output pair generation  
- Fine-tuning via Hugging Face Trainer  
- Validation + evaluation metrics  
- Saving the trained model to local `artifacts/` directory  

This results in a summarization model that produces **clearer, more human-like summaries**.

## ğŸš€ FastAPI Deployment  
The project includes a full **FastAPI service** for real-time summarization.

### âœ” Built-in Endpoints
- `/` â†’ redirected to the docs  
- `/train` â†’ to train the model  
- `/predict` â†’ to make prediction
  


## ğŸ§± Architecture & Pipeline Design

The entire summarization workflow is structured into **modular components**, enabling reuse, testing, and easy upgrades.

### ğŸ“ Folder Structure

```
textsummarizer/
â”‚
â”œâ”€â”€ app.py # Optional API / CLI interface
â”œâ”€â”€ main.py # Main entry point for pipeline execution
â”‚
â”œâ”€â”€ src/
â”‚ â””â”€â”€ textSummarizer/
â”‚ â”œâ”€â”€ components/ # Core modules: ingestion, processing, summarization
â”‚ â”œâ”€â”€ config/ # Centralized configuration handling
â”‚ â”œâ”€â”€ constants/ # Project-level constants
â”‚ â”œâ”€â”€ entity/ # Config entities (dataclasses)
â”‚ â”œâ”€â”€ logging/ # Project-wide logger
â”‚ â”œâ”€â”€ pipeline/ # High-level pipeline orchestration
â”‚ â””â”€â”€ utils/ # Helpers for paths, reading text, tokenization
â”‚
â”œâ”€â”€ config/ # Additional config resources
â”œâ”€â”€ research/ # Notebooks for experimentation
â”‚
â”œâ”€â”€ params.yaml # YAML-driven pipeline settings
â”œâ”€â”€ requirements.txt # Project dependencies
â”œâ”€â”€ Dockerfile # Docker deployment
â”œâ”€â”€ setup.py # Packaging for pip install
â”œâ”€â”€ template.py # Template code for module scaffolding
â””â”€â”€ README.md

```

## ğŸ” How The Pipeline Works

### 1ï¸âƒ£ **Configuration Layer**
Located in:

src/textSummarizer/config
src/textSummarizer/entity
params.yaml

- YAML inputs define the summarization parameters  
- Config + Entity classes convert YAML into strongly typed objects  
- Centralized settings ensure pipeline reproducibility  

### 2ï¸âƒ£ **Components Layer (Core Processing)**

Found under:
```
src/textSummarizer/components/
```

Typical components include:

- data_ingestion  
- data_transformation 
- model_trainer 
- model_evaluation

Each component is its own class/module, making the system **clean and maintainable**.

### 3ï¸âƒ£ **Pipeline Layer**

Found under:
```
src/textSummarizer/pipeline/
```

This layer orchestrates the full text-summarization training flow:

data_ingestion â†’ data_transformation  â†’ model_trainer 
 â†’ model_evaluation.

## ğŸ§  Methodology

Depending on configuration, the summarizer can support:

- **Extractive summarization** (identifying key sentences)  
- **Abstractive summarization** (model-generated rewriting)  
- **Hybrid methods**  

The architecture is model-agnostic, meaning:

- You can plug in your own LLM  
- Add a Hugging Face transformer  
- Integrate OpenAI/Cohere APIs  
- Extend chunking to support long-context models  

This modularity is exactly how enterprise ML teams structure scalable NLP services.

---

## âš™ï¸ Tech Stack

### **Languages & Frameworks**
- Python 3.x  
- PyYAML  
- PyTorch / Transformers (if integrated)  
- FastAPI for Model serving 
- LLMs
- Nltk

### **Infrastructure**
- Docker   
- CLI runtime  
- YAML-driven configuration  

### **Development**
- Modular ML design  
- OOP-based component abstraction  
- Logging + utilities  
- Research notebooks  

---

## ğŸš€ Running the Project

### 1ï¸âƒ£ Local Installation

```bash
git clone <repo-url>
cd textsummarizer

python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

pip install -r requirements.txt
python3 app.py

```

Happy Coding!!!

